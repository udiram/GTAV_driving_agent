{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathy\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "Scipy not supported!\n"
     ]
    }
   ],
   "source": [
    "import os, cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.screen_grab import grab_screen\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "from models.models import inception_v3 as googlenet\n",
    "from random import shuffle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "FILE_I_END = 21\n",
    "\n",
    "WIDTH = 480\n",
    "HEIGHT = 270\n",
    "LR = 1e-3\n",
    "EPOCHS = 30\n",
    "\n",
    "MODEL_NAME = ''\n",
    "PREV_MODEL = ''\n",
    "LOAD_MODEL = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathy\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tflearn\\initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\sathy\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\sathy\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sathy\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = googlenet(WIDTH, HEIGHT, 3, LR, output=9, model_name=MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# print(np.load('data/training_data-1058.npy', allow_pickle=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1997  | total loss: \u001B[1m\u001B[32m0.02764\u001B[0m\u001B[0m | time: 4.159s\n",
      "| Momentum | epoch: 250 | loss: 0.02764 - acc: 0.9950 -- iter: 320/450\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m test_x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([i[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m test])\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, WIDTH, HEIGHT, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m     20\u001B[0m test_y \u001B[38;5;241m=\u001B[39m [i[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m test]\n\u001B[1;32m---> 22\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtargets\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_set\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_x\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtargets\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_y\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43msnapshot_step\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2500\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_metric\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m count \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAVING MODEL!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tflearn\\models\\dnn.py:196\u001B[0m, in \u001B[0;36mDNN.fit\u001B[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# Retrieve data preprocesing and augmentation\u001B[39;00m\n\u001B[0;32m    195\u001B[0m daug_dict, dprep_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretrieve_data_preprocessing_and_augmentation()\n\u001B[1;32m--> 196\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeed_dicts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_feed_dicts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_feed_dicts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mn_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mshow_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m                 \u001B[49m\u001B[43msnapshot_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msnapshot_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m                 \u001B[49m\u001B[43msnapshot_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msnapshot_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    201\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mshuffle_all\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mdprep_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdprep_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mdaug_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdaug_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mexcl_trainops\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexcl_trainops\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    205\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tflearn\\helpers\\trainer.py:341\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, train_op \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_ops):\n\u001B[0;32m    339\u001B[0m     caller\u001B[38;5;241m.\u001B[39mon_sub_batch_begin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_state)\n\u001B[1;32m--> 341\u001B[0m     snapshot \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_state\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[43m                               \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_checkpoint_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m|\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msnapshot_epoch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[43m                               \u001B[49m\u001B[43msnapshot_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m                               \u001B[49m\u001B[43mshow_metric\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    346\u001B[0m     \u001B[38;5;66;03m# Update training state\u001B[39;00m\n\u001B[0;32m    347\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_state\u001B[38;5;241m.\u001B[39mupdate(train_op, train_ops_count)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tflearn\\helpers\\trainer.py:827\u001B[0m, in \u001B[0;36mTrainOp._train\u001B[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001B[0m\n\u001B[0;32m    825\u001B[0m feed_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_dflow\u001B[38;5;241m.\u001B[39mnext()\n\u001B[0;32m    826\u001B[0m tflearn\u001B[38;5;241m.\u001B[39mis_training(\u001B[38;5;28;01mTrue\u001B[39;00m, session\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession)\n\u001B[1;32m--> 827\u001B[0m _, train_summ_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msumm_op\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    828\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mfeed_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;66;03m# Retrieve loss value from summary string\u001B[39;00m\n\u001B[0;32m    831\u001B[0m sname \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope_name\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001B[0m, in \u001B[0;36mBaseSession.run\u001B[1;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m    965\u001B[0m run_metadata_ptr \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_NewBuffer() \u001B[38;5;28;01mif\u001B[39;00m run_metadata \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    967\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 968\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions_ptr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mrun_metadata_ptr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    970\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m run_metadata:\n\u001B[0;32m    971\u001B[0m     proto_data \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001B[0m, in \u001B[0;36mBaseSession._run\u001B[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001B[39;00m\n\u001B[0;32m   1189\u001B[0m \u001B[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001B[39;00m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m final_fetches \u001B[38;5;129;01mor\u001B[39;00m final_targets \u001B[38;5;129;01mor\u001B[39;00m (handle \u001B[38;5;129;01mand\u001B[39;00m feed_dict_tensor):\n\u001B[1;32m-> 1191\u001B[0m   results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_targets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_fetches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1192\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mfeed_dict_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1193\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1194\u001B[0m   results \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001B[0m, in \u001B[0;36mBaseSession._do_run\u001B[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1368\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1371\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_run_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeeds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1372\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1373\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001B[0m, in \u001B[0;36mBaseSession._do_call\u001B[1;34m(self, fn, *args)\u001B[0m\n\u001B[0;32m   1376\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_do_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m   1377\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1379\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOpError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1380\u001B[0m     message \u001B[38;5;241m=\u001B[39m compat\u001B[38;5;241m.\u001B[39mas_text(e\u001B[38;5;241m.\u001B[39mmessage)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001B[0m, in \u001B[0;36mBaseSession._do_run.<locals>._run_fn\u001B[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_fn\u001B[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001B[0;32m   1359\u001B[0m   \u001B[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001B[39;00m\n\u001B[0;32m   1360\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extend_graph()\n\u001B[1;32m-> 1361\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_tf_sessionrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetch_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1362\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mtarget_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\GTAV_driving_agent\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001B[0m, in \u001B[0;36mBaseSession._call_tf_sessionrun\u001B[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[0;32m   1452\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_tf_sessionrun\u001B[39m(\u001B[38;5;28mself\u001B[39m, options, feed_dict, fetch_list, target_list,\n\u001B[0;32m   1453\u001B[0m                         run_metadata):\n\u001B[1;32m-> 1454\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_SessionRun_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1455\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mfetch_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1456\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "##    data_order = [i for i in range(1,FILE_I_END+1)]\n",
    "    data_order = [i for i in range(1, FILE_I_END + 1)]\n",
    "    shuffle(data_order)\n",
    "    for count, i in enumerate(data_order):\n",
    "        try:\n",
    "            file_name = 'data/training_data-{0}.npy'.format(i)\n",
    "            # full file info\n",
    "            train_data = np.load(file_name, allow_pickle=True)\n",
    "            print('data/training_data-{0}.npy'.format(i), len(train_data))\n",
    "\n",
    "\n",
    "            train = train_data[:-50]\n",
    "            test = train_data[-50:]\n",
    "\n",
    "            X = np.array([i[0] for i in train]).reshape(-1, WIDTH, HEIGHT, 3)\n",
    "            Y = [i[1] for i in train]\n",
    "\n",
    "            test_x = np.array([i[0] for i in test]).reshape(-1, WIDTH, HEIGHT, 3)\n",
    "            test_y = [i[1] for i in test]\n",
    "\n",
    "            model.fit({'input': X}, {'targets': Y}, n_epoch = 1, validation_set = ({'input': test_x}, {'targets': test_y}),\n",
    "                snapshot_step = 2500, show_metric = True, run_id = MODEL_NAME)\n",
    "\n",
    "            if count % 10 == 0:\n",
    "                print('SAVING MODEL!')\n",
    "                model.save(MODEL_NAME)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}